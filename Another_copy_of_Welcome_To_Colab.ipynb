{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amirno/opencv/blob/master/Another_copy_of_Welcome_To_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "19V173CMyccZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate,Flatten,Dense,Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "xfi3NXzOyzeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import struct\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "\n",
        "def __convert_to_one_hot(vector, num_classes):\n",
        "    result = np.zeros(shape=[len(vector), num_classes])\n",
        "    result[np.arange(len(vector)), vector] = 1\n",
        "    return result\n",
        "\n",
        "\n",
        "def __resize_image(src_image, dst_image_height, dst_image_width):\n",
        "    src_image_height = src_image.shape[0]\n",
        "    src_image_width = src_image.shape[1]\n",
        "\n",
        "    if src_image_height > dst_image_height or src_image_width > dst_image_width:\n",
        "        height_scale = dst_image_height / src_image_height\n",
        "        width_scale = dst_image_width / src_image_width\n",
        "        scale = min(height_scale, width_scale)\n",
        "        img = cv2.resize(src=src_image, dsize=(0, 0), fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)\n",
        "    else:\n",
        "        img = src_image\n",
        "\n",
        "    img_height = img.shape[0]\n",
        "    img_width = img.shape[1]\n",
        "\n",
        "    dst_image = np.zeros(shape=[dst_image_height, dst_image_width], dtype=np.uint8)\n",
        "\n",
        "    y_offset = (dst_image_height - img_height) // 2\n",
        "    x_offset = (dst_image_width - img_width) // 2\n",
        "\n",
        "    dst_image[y_offset:y_offset+img_height, x_offset:x_offset+img_width] = img\n",
        "\n",
        "    return dst_image\n",
        "\n",
        "\n",
        "def read_hoda_cdb(file_name):\n",
        "    with open(file_name, 'rb') as binary_file:\n",
        "\n",
        "        data = binary_file.read()\n",
        "\n",
        "        offset = 0\n",
        "\n",
        "        # read private header\n",
        "\n",
        "        yy = struct.unpack_from('H', data, offset)[0]\n",
        "        offset += 2\n",
        "\n",
        "        m = struct.unpack_from('B', data, offset)[0]\n",
        "        offset += 1\n",
        "\n",
        "        d = struct.unpack_from('B', data, offset)[0]\n",
        "        offset += 1\n",
        "\n",
        "        H = struct.unpack_from('B', data, offset)[0]\n",
        "        offset += 1\n",
        "\n",
        "        W = struct.unpack_from('B', data, offset)[0]\n",
        "        offset += 1\n",
        "\n",
        "        TotalRec = struct.unpack_from('I', data, offset)[0]\n",
        "        offset += 4\n",
        "\n",
        "        LetterCount = struct.unpack_from('128I', data, offset)\n",
        "        offset += 128 * 4\n",
        "\n",
        "        imgType = struct.unpack_from('B', data, offset)[0]  # 0: binary, 1: gray\n",
        "        offset += 1\n",
        "\n",
        "        Comments = struct.unpack_from('256c', data, offset)\n",
        "        offset += 256 * 1\n",
        "\n",
        "        Reserved = struct.unpack_from('245c', data, offset)\n",
        "        offset += 245 * 1\n",
        "\n",
        "        if (W > 0) and (H > 0):\n",
        "            normal = True\n",
        "        else:\n",
        "            normal = False\n",
        "\n",
        "        images = []\n",
        "        labels = []\n",
        "\n",
        "        for i in range(TotalRec):\n",
        "\n",
        "            StartByte = struct.unpack_from('B', data, offset)[0]  # must be 0xff\n",
        "            offset += 1\n",
        "\n",
        "            label = struct.unpack_from('B', data, offset)[0]\n",
        "            offset += 1\n",
        "\n",
        "            if not normal:\n",
        "                W = struct.unpack_from('B', data, offset)[0]\n",
        "                offset += 1\n",
        "\n",
        "                H = struct.unpack_from('B', data, offset)[0]\n",
        "                offset += 1\n",
        "\n",
        "            ByteCount = struct.unpack_from('H', data, offset)[0]\n",
        "            offset += 2\n",
        "\n",
        "            image = np.zeros(shape=[H, W], dtype=np.uint8)\n",
        "\n",
        "            if imgType == 0:\n",
        "                # Binary\n",
        "                for y in range(H):\n",
        "                    bWhite = True\n",
        "                    counter = 0\n",
        "                    while counter < W:\n",
        "                        WBcount = struct.unpack_from('B', data, offset)[0]\n",
        "                        offset += 1\n",
        "                        # x = 0\n",
        "                        # while x < WBcount:\n",
        "                        #     if bWhite:\n",
        "                        #         image[y, x + counter] = 0  # Background\n",
        "                        #     else:\n",
        "                        #         image[y, x + counter] = 255  # ForeGround\n",
        "                        #     x += 1\n",
        "                        if bWhite:\n",
        "                            image[y, counter:counter + WBcount] = 0  # Background\n",
        "                        else:\n",
        "                            image[y, counter:counter + WBcount] = 255  # ForeGround\n",
        "                        bWhite = not bWhite  # black white black white ...\n",
        "                        counter += WBcount\n",
        "            else:\n",
        "                # GrayScale mode\n",
        "                data = struct.unpack_from('{}B'.format(W * H), data, offset)\n",
        "                offset += W * H\n",
        "                image = np.asarray(data, dtype=np.uint8).reshape([W, H]).T\n",
        "\n",
        "            images.append(image)\n",
        "            labels.append(label)\n",
        "\n",
        "        return images, labels\n",
        "\n",
        "\n",
        "def read_hoda_dataset(dataset_path, images_height=32, images_width=32, one_hot=False, reshape=True):\n",
        "    images, labels = read_hoda_cdb(dataset_path)\n",
        "    assert len(images) == len(labels)\n",
        "\n",
        "    X = np.zeros(shape=[len(images), images_height, images_width], dtype=np.float32)\n",
        "    Y = np.zeros(shape=[len(labels)], dtype=np.int64)\n",
        "\n",
        "    for i in range(len(images)):\n",
        "        image = images[i]\n",
        "        # Image resizing.\n",
        "        image = __resize_image(src_image=image, dst_image_height=images_height, dst_image_width=images_width)\n",
        "        # Image normalization.\n",
        "        image = image / 255\n",
        "        # Image binarization.\n",
        "        image = np.where(image >= 0.5, 1, 0)\n",
        "        # Image.\n",
        "        X[i] = image\n",
        "        # Label.\n",
        "        Y[i] = labels[i]\n",
        "\n",
        "    if one_hot:\n",
        "        Y = __convert_to_one_hot(Y, 10).astype(dtype=np.float32)\n",
        "    else:\n",
        "        Y = Y.astype(dtype=np.float32)\n",
        "\n",
        "    if reshape:\n",
        "        X = X.reshape(-1, images_height * images_width)\n",
        "    else:\n",
        "        X = X.reshape(-1, images_height, images_width, 1)\n",
        "\n",
        "    return X, Y\n"
      ],
      "metadata": {
        "id": "_cICMNqu1dbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define U-Net model architecture\n",
        "def unet_model_b(input_shape, num_classes):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "    # Contracting path\n",
        "    conv1 = layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\")(inputs)\n",
        "    conv1 = layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\")(conv1)\n",
        "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(pool1)\n",
        "    conv2 = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(conv2)\n",
        "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(pool2)\n",
        "    conv3 = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(conv3)\n",
        "    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\")(pool3)\n",
        "    conv4 = layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\")(conv4)\n",
        "    drop4 = layers.Dropout(0.5)(conv4)\n",
        "    pool4 = layers.MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "    # Bottom\n",
        "    conv5 = layers.Conv2D(512, 3, activation=\"relu\", padding=\"same\")(pool4)\n",
        "    conv5 = layers.Conv2D(512, 3, activation=\"relu\", padding=\"same\")(conv5)\n",
        "    drop5 = layers.Dropout(0.5)(conv5)\n",
        "\n",
        "    # Expansive path\n",
        "    up6 = layers.Conv2D(256, 2, activation=\"relu\", padding=\"same\")(layers.UpSampling2D(size=(2, 2))(drop5))\n",
        "    merge6 = layers.concatenate([drop4, up6], axis=3)\n",
        "    conv6 = layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\")(merge6)\n",
        "    conv6 = layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\")(conv6)\n",
        "\n",
        "    up7 = layers.Conv2D(128, 2, activation=\"relu\", padding=\"same\")(layers.UpSampling2D(size=(2, 2))(conv6))\n",
        "    merge7 = layers.concatenate([conv3, up7], axis=3)\n",
        "    conv7 = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(merge7)\n",
        "    conv7 = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(conv7)\n",
        "\n",
        "    up8 = layers.Conv2D(64, 2, activation=\"relu\", padding=\"same\")(layers.UpSampling2D(size=(2, 2))(conv7))\n",
        "    merge8 = layers.concatenate([conv2, up8], axis=3)\n",
        "    conv8 = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(merge8)\n",
        "    conv8 = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(conv8)\n",
        "\n",
        "    up9 = layers.Conv2D(32, 2, activation=\"relu\", padding=\"same\")(layers.UpSampling2D(size=(2, 2))(conv8))\n",
        "    merge9 = layers.concatenate([conv1, up9], axis=3)\n",
        "    conv9 = layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\")(merge9)\n",
        "    conv9 = layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\")(conv9)\n",
        "    conv9 = layers.Conv2D(1, 3, activation=\"relu\", padding=\"same\")(conv9)\n",
        "    conv9 = layers.Flatten()(conv9)\n",
        "    conv9 = layers.Dense(100, activation=\"relu\")(conv9)\n",
        "    #output = layers.Conv2D(10, (1, 1), activation='softmax')(conv9)\n",
        "    conv9 = layers.Dense(num_classes, activation=\"softmax\")(conv9)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=conv9)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "7ig9C6B-y-O4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def augmanet(x_train,y_train):\n",
        "# Define the augmentation parameters\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=10,\n",
        "        zoom_range=0.1,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1\n",
        "        )\n",
        "\n",
        "# Fit the data generator on the training data\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Generate augmented images\n",
        "    augmented_images = []\n",
        "    augmented_labels = []\n",
        "\n",
        "    for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=50000, shuffle=True):\n",
        "        augmented_images.append(x_batch)\n",
        "        augmented_labels.append(y_batch)\n",
        "        break\n",
        "\n",
        "    # Convert augmented images and labels to arrays\n",
        "    augmented_images = np.array(augmented_images).reshape(-1, 32, 32, 1)\n",
        "    augmented_labels = np.array(augmented_labels).reshape(-1)\n",
        "\n",
        "    # Concatenate augmented data with original data\n",
        "    x_train_augmented = np.concatenate((x_train, augmented_images))\n",
        "    y_train_augmented = np.concatenate((y_train, augmented_labels))\n",
        "    return x_train_augmented,y_train_augmented"
      ],
      "metadata": {
        "id": "BDkNbz3Ny7-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unet_new(input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Encoding path\n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    # Bottleneck\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
        "\n",
        "    # Decoding path\n",
        "    up4 = UpSampling2D(size=(2, 2))(conv3)\n",
        "    up4 = Conv2D(64, (3, 3), activation='relu', padding='same')(up4)\n",
        "    merge4 = concatenate([conv2, up4], axis=3)\n",
        "    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(merge4)\n",
        "    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv4)\n",
        "\n",
        "    up5 = UpSampling2D(size=(2, 2))(conv4)\n",
        "    up5 = Conv2D(32, (3, 3), activation='relu', padding='same')(up5)\n",
        "    merge5 = concatenate([conv1, up5], axis=3)\n",
        "    conv5 = Conv2D(32, (3, 3), activation='relu', padding='same')(merge5)\n",
        "    conv5 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv5)\n",
        "    conv5 = Conv2D(16, (3, 3), activation='relu', padding='same')(conv5)\n",
        "    conv5 = Conv2D(8, (3, 3), activation='relu', padding='same')(conv5)\n",
        "    conv5 = Conv2D(1, (3, 3), activation='relu', padding='same')(conv5)\n",
        "    conv5 = Flatten()(conv5)\n",
        "    conv5 = Dense(400, activation='relu')(conv5)\n",
        "    conv5 = Dense(100, activation='relu')(conv5)\n",
        "    conv5=Dropout(0.4)(conv5)\n",
        "    # Output\n",
        "    output = Dense(10, activation='softmax')(conv5)\n",
        "\n",
        "    return Model(inputs, output)"
      ],
      "metadata": {
        "id": "_Jhr71a3zINo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unet(input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Encoding path\n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    # Bottleneck\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
        "\n",
        "    # Decoding path\n",
        "    up4 = UpSampling2D(size=(2, 2))(conv3)\n",
        "    up4 = Conv2D(64, (3, 3), activation='relu', padding='same')(up4)\n",
        "    merge4 = concatenate([conv2, up4], axis=3)\n",
        "    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(merge4)\n",
        "    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv4)\n",
        "\n",
        "    up5 = UpSampling2D(size=(2, 2))(conv4)\n",
        "    up5 = Conv2D(32, (3, 3), activation='relu', padding='same')(up5)\n",
        "    merge5 = concatenate([conv1, up5], axis=3)\n",
        "    conv5 = Conv2D(32, (3, 3), activation='relu', padding='same')(merge5)\n",
        "    conv5 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv5)\n",
        "    conv5 = Conv2D(1, (5, 5), activation='relu', padding='same')(conv5)\n",
        "    conv5=Dropout(0.4)(conv5)\n",
        "    conv5 = Flatten()(conv5)\n",
        "    conv5 = Dense(100, activation='relu')(conv5)\n",
        "    # Output\n",
        "    output = Dense(10, activation='softmax')(conv5)\n",
        "\n",
        "    return Model(inputs, output)"
      ],
      "metadata": {
        "id": "IYxQ-PEDzItR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = read_hoda_dataset(dataset_path='./HDR/Train 60000.cdb',\n",
        "                                images_height=32,\n",
        "                                images_width=32,\n",
        "                                one_hot=False,\n",
        "                                reshape=False)\n",
        "print('Reading test dataset (Test 20000.cdb)...')\n",
        "X_test, Y_test = read_hoda_dataset(dataset_path='./HDR/Test 20000.cdb',\n",
        "                              images_height=32,\n",
        "                              images_width=32,\n",
        "                              one_hot=False,\n",
        "                              reshape=False)\n",
        "\n",
        "print('Reading remaining samples dataset (RemainingSamples.cdb)...')\n",
        "X_remain, Y_remain = read_hoda_dataset('./HDR/RemainingSamples.cdb',\n",
        "                                             images_height=32,\n",
        "                                             images_width=32,\n",
        "                                             one_hot=False,\n",
        "                                             reshape=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "Uvp2Jt4E3lWp",
        "outputId": "15be0437-ee7b-4694-d638-a099b4f9795e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading test dataset (Test 20000.cdb)...\n",
            "Reading remaining samples dataset (RemainingSamples.cdb)...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[X_train,Y_train]=augmanet(X_train,Y_train)"
      ],
      "metadata": {
        "id": "H3DKAMCr410n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_remain=X_remain.reshape((22352,32,32))\n",
        "X_train=X_train.reshape((110000,32,32))\n",
        "    # X_train=X_train.astype('float32')/255\n",
        "X_test=X_test.reshape((20000,32,32))\n",
        "    # X_test=X_test.astype('float32')/255\n"
      ],
      "metadata": {
        "id": "O6qX6_v57ouH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train=to_categorical(Y_train)\n",
        "Y_test=to_categorical(Y_test)\n",
        "Y_remain=to_categorical(Y_remain)\n",
        "input_shape = (32, 32, 1)\n",
        "num_classes = 10"
      ],
      "metadata": {
        "id": "UpmSg5AB5GZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create the U-Net model\n",
        "#model = unet_model_b(input_shape, num_classes)\n",
        "model = unet_new(input_shape)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "# Train the model\n",
        "# Assuming you have your training data and labels as X_train and y_train\n",
        "#model.fit(X_train, Y_train, batch_size=256, epochs=1,validation_data=(X_test,Y_test))\n",
        "h=model.fit(X_train, Y_train, batch_size=256, epochs=10,validation_data=(X_remain,Y_remain))\n",
        "#model.fit(X_train, Y_train, batch_size=128, epochs=10,validation_split=0.2)\n",
        "#99.34\n",
        "\n",
        "#Apologies for the incomplete code. Here's the complete code snippet for training the U-Net model for Persian handwritten digit recognition:\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, Y_test)\n",
        "\n",
        "# Make predictions on new data\n",
        "# Assuming you have new data as X_new\n",
        "predictions = model.predict(X_test)"
      ],
      "metadata": {
        "id": "D5V3sdUW4_om",
        "outputId": "2731ac3f-1949-4c9c-8baa-e7824b1aa1d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m  3/430\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m58:41\u001b[0m 8s/step - accuracy: 0.1115 - loss: 2.2996"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}